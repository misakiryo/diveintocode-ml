{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, *shape):\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    \n",
    "    def B(self, *shape):\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return\n",
    "    \n",
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW ** 2\n",
    "        self.HB += layer.dB ** 2\n",
    "        layer.W -= self.lr * np.sqrt(1 / self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1 / self.HB) * layer.dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 1.\n",
    "class Conv2d_3:\n",
    "    def __init__(self, filter_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0, st=1):\n",
    "        self.optimizer = optimizer\n",
    "        if type(filter_size) == int:\n",
    "            self.filter_size_h = self.filter_size_w = filter_size\n",
    "        else:\n",
    "            self.filter_size_h = filter_size[0]\n",
    "            self.filter_size_w = filter_size[1]\n",
    "        if type(pa) == int:\n",
    "            self.pa_h = self.pa_w = pa\n",
    "        else:\n",
    "            self.pa_h = pa[0]\n",
    "            self.pa_w = pa[1]\n",
    "        if type(st) == int:\n",
    "            self.st_h = self.st_w = st\n",
    "        else:\n",
    "            self.st_h = st[0]\n",
    "            self.st_w = st[1]\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, self.filter_size_h, self.filter_size_w)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out_h = None\n",
    "        self.n_out_w = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_in_h = X.shape[-2]\n",
    "        self.n_in_w = X.shape[-1]\n",
    "        self.n_out_h = out_size(self.n_in_h, self.filter_size_h, self.pa_h, self.st_h)\n",
    "        self.n_out_w = out_size(self.n_in_w, self.filter_size_w, self.pa_w, self.st_w)\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in_h, self.n_in_w)\n",
    "        \n",
    "        self.X = np.pad(X, ((0, 0), (0, 0), ((self.filter_size_h-1), 0), ((self.filter_size_w-1), 0)))\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.filter_size_h,\n",
    "                            self.filter_size_w, self.n_in_h+(self.filter_size_h-1), self.n_in_w+(self.filter_size_w-1)))\n",
    "        for i in range(self.filter_size_h):\n",
    "            for j in range(self.filter_size_w):\n",
    "                self.X1[:, :, i, j] = np.roll(self.X, (-i, -j), axis=(-2, -1))\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, :, self.filter_size_h-1-self.pa_h:self.n_in_h+self.pa_h:self.st_h,\n",
    "                          self.filter_size_w-1-self.pa_w:self.n_in_w+self.pa_w:self.st_w]*self.W[:, : , :, :, np.newaxis,\n",
    "                                                                                                 np.newaxis], axis=(2, 3, 4)) + self.B.reshape(-1, 1, 1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis, np.newaxis]*\\\n",
    "                         self.X1[:, np.newaxis, :, :, :,self.filter_size_h-1-self.pa_h:self.n_in_h+self.pa_h:self.st_h,\\\n",
    "                                 self.filter_size_w-1-self.pa_w:self.n_in_w+self.pa_w:self.st_w], axis=(0, -2, -1))\n",
    "        self.dB = np.sum(dA, axis=(0, -2, -1))\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, 0), (0, (self.filter_size_h-1)), (0, (self.filter_size_w-1))))\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.filter_size_h,\\\n",
    "                             self.filter_size_w, self.dA.shape[-2],self.dA.shape[-1]))\n",
    "        for i in range(self.filter_size_h):\n",
    "            for j in range(self.filter_size_w):\n",
    "                self.dA1[:, :, i, j] = np.roll(self.dA, (i, j), axis=(-2, -1))\n",
    "        dX = np.sum(self.W[:, :, :, :, np.newaxis, np.newaxis] * self.dA1[:, :, np.newaxis, np.newaxis], axis=(1, 4, 5))\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(in_size, f, p=0, s=1):\n",
    "    return int((in_size+2*p-f) // s) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1\n",
    "conv2d_3 = Conv2d_3(filter_size=[1, 3], initializer=SimpleInitializer(0.01), optimizer=SGD(0.01),\\\n",
    "                    n_in_channels=1, n_out_channels=1, pa=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[[1,5,0,2,8,1], [1,5,0,2,8,1]]], [[[1,5,0,2,8,1], [1,5,0,2,8,1]]]])\n",
    "conv2d_3.W = np.array([[[[-1, 2, -1]]]], dtype=float)\n",
    "conv2d_3.B = np.array([0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 2, 6)\n",
      "(1, 1, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(conv2d_3.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 5, 0, 2, 8, 1],\n",
       "         [1, 5, 0, 2, 8, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 5, 0, 2, 8, 1],\n",
       "         [1, 5, 0, 2, 8, 1]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 9. -7. -4. 13.]\n",
      "   [ 9. -7. -4. 13.]]]\n",
      "\n",
      "\n",
      " [[[ 9. -7. -4. 13.]\n",
      "   [ 9. -7. -4. 13.]]]]\n"
     ]
    }
   ],
   "source": [
    "a = conv2d_3.forward(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[-1.,  0.,  0.,  0.,  5., -4.],\n",
       "          [-1.,  0.,  0.,  0.,  5., -4.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[-1.,  0.,  0.,  0.,  5., -4.],\n",
       "          [-1.,  0.,  0.,  0.,  5., -4.]]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[[[1,2,3,4], [1,2,3,4]]], [[[1,2,3,4], [1,2,3,4]]]])\n",
    "delta_x = conv2d_3.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 76., 172., 128.]]]]), array([40]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv2d_3.dW\n",
    "delta_b = conv2d_3.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2\n",
    "conv2d_3 = Conv2d_3(filter_size=[1, 3], initializer=SimpleInitializer(0.01), \\\n",
    "                    optimizer=SGD(0.01), n_in_channels=2,n_out_channels=3, pa=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1., 2.]],\n",
       "\n",
       "        [[2., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[2., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[[1, 2, 3, 4], [1, 2, 3, 4]], [[2, 3, 4, 5], [2, 3, 4, 5]]]])\n",
    "conv2d_3.W = np.ones((3, 2, 1, 3), dtype=float) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズh, フィルタサイズw)である。\n",
    "#\"\"\"\n",
    "conv2d_3.W[0,0,0,2] = 2\n",
    "conv2d_3.W[0,1,0,0] = 2\n",
    "conv2d_3.W[1,0,0,0] = 2\n",
    "#\"\"\n",
    "conv2d_3.B = np.array([1, 2, 3], dtype=float) # （出力チャンネル数）\n",
    "conv2d_3.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 4)\n",
      "(3, 2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(conv2d_3.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 2, 3, 4],\n",
       "         [1, 2, 3, 4]],\n",
       "\n",
       "        [[2, 3, 4, 5],\n",
       "         [2, 3, 4, 5]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[21. 29.]\n",
      "   [21. 29.]]\n",
      "\n",
      "  [[18. 25.]\n",
      "   [18. 25.]]\n",
      "\n",
      "  [[18. 24.]\n",
      "   [18. 24.]]]]\n"
     ]
    }
   ],
   "source": [
    "a = conv2d_3.forward(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 93., 195., 288., 204.],\n",
       "          [ 93., 195., 288., 204.]],\n",
       "\n",
       "         [[186., 297., 195., 102.],\n",
       "          [186., 297., 195., 102.]]],\n",
       "\n",
       "\n",
       "        [[[186., 297., 195., 102.],\n",
       "          [186., 297., 195., 102.]],\n",
       "\n",
       "         [[ 93., 195., 195., 102.],\n",
       "          [ 93., 195., 195., 102.]]],\n",
       "\n",
       "\n",
       "        [[[ 93., 195., 195., 102.],\n",
       "          [ 93., 195., 195., 102.]],\n",
       "\n",
       "         [[ 93., 195., 195., 102.],\n",
       "          [ 93., 195., 195., 102.]]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[[[9, 11], [9, 11]], [[32, 35], [32, 35]], [[52, 56], [52, 56]]]])\n",
    "delta_x = conv2d_3.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 62., 102., 142.]],\n",
       " \n",
       "         [[102., 142., 182.]]],\n",
       " \n",
       " \n",
       "        [[[204., 338., 472.]],\n",
       " \n",
       "         [[338., 472., 606.]]],\n",
       " \n",
       " \n",
       "        [[[328., 544., 760.]],\n",
       " \n",
       "         [[544., 760., 976.]]]]),\n",
       " array([ 40, 134, 216]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv2d_3.dW\n",
    "delta_b = conv2d_3.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 3.\n",
    "#Ploblem1に out_size 関数を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 4.\n",
    "class MaxPool2D:\n",
    "    def __init__(self, st):\n",
    "        self.st_h = st[0]\n",
    "        self.st_w = st[1]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_in_channels, self.n_in_h, self.n_in_w = X.shape\n",
    "        A = np.zeros((self.n_samples, self.n_in_channels, self.n_in_h//self.st_h, self.n_in_w//self.st_w))\n",
    "        self.Aij = np.zeros(((self.n_in_h*self.n_in_w)//(self.st_h*self.st_w), X.ndim), dtype=int)\n",
    "        for t in range(self.n_samples):\n",
    "            for m in range(self.n_in_channels):\n",
    "                for i in range(self.n_in_h//self.st_h):\n",
    "                    for j in range(self.n_in_w//self.st_w):\n",
    "                        X1 = X[t, m, i*self.st_h:(i+1)*self.st_h, j*self.st_w:(j+1)*self.st_w]\n",
    "                        A[t, m, i, j] = np.max(X1)\n",
    "                        idx = np.argmax(X1)\n",
    "                        self.Aij[i*(self.n_in_w//self.st_w) + j] =np.array([t, m, i*self.st_h + idx//self.st_h, j*self.st_w + idx\\\n",
    "                                                                           %self.st_h], dtype=int)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        a = np.zeros(self.X.shape)\n",
    "        a[tuple(self.Aij.T)] =1\n",
    "        return a*dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 9. 11. 13. 15.]\n",
      "   [25. 27. 29. 31.]\n",
      "   [41. 43. 45. 47.]]]]\n",
      "[[0 0 1 1]\n",
      " [0 0 1 3]\n",
      " [0 0 1 5]\n",
      " [0 0 1 7]\n",
      " [0 0 3 1]\n",
      " [0 0 3 3]\n",
      " [0 0 3 5]\n",
      " [0 0 3 7]\n",
      " [0 0 5 1]\n",
      " [0 0 5 3]\n",
      " [0 0 5 5]\n",
      " [0 0 5 7]]\n"
     ]
    }
   ],
   "source": [
    "maxpool2d = MaxPool2D([2,2])\n",
    "print(maxpool2d.forward(np.arange(1*1*6*8).reshape(1,1,6,8)))\n",
    "print(maxpool2d.Aij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  9.,  0., 11.,  0., 13.,  0., 15.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0., 25.,  0., 27.,  0., 29.,  0., 31.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0., 41.,  0., 43.,  0., 45.,  0., 47.]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool2d.backward(np.arange(1*1*6*8).reshape(1,1,6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 5(Advance).\n",
    "class AveragePool2D:\n",
    "    def __init__(self, st):\n",
    "        self.st_h = st[0]\n",
    "        self.st_w = st[1]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_in_channels, self.n_in_h, self.n_in_w = X.shape\n",
    "        A = np.zeros((self.n_samples, self.n_in_channels, self.n_in_h//self.st_h, self.n_in_w//self.st_w))\n",
    "        for t in range(self.n_samples):\n",
    "            for m in range(self.n_in_channels):\n",
    "                for i in range(self.n_in_h//self.st_h):\n",
    "                    for j in range(self.n_in_w//self.st_w):\n",
    "                        X1 = X[t, m, i*self.st_h:(i+1)*self.st_h, j*self.st_w:(j+1)*self.st_w]\n",
    "                        A[t, m, i, j] = np.average(X1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 4.5  6.5  8.5 10.5]\n",
      "   [20.5 22.5 24.5 26.5]\n",
      "   [36.5 38.5 40.5 42.5]]]]\n"
     ]
    }
   ],
   "source": [
    "averagepool2d = AveragePool2D([2,2])\n",
    "print(averagepool2d.forward(np.arange(1*1*6*8).reshape(1,1,6,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "         [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "         [24, 25, 26, 27, 28, 29, 30, 31],\n",
       "         [32, 33, 34, 35, 36, 37, 38, 39],\n",
       "         [40, 41, 42, 43, 44, 45, 46, 47]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averagepool2d.backward(np.arange(1*1*6*8).reshape(1,1,6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 6.\n",
    "class Flatten:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.n_samples, self.n_out_channels, self.n_out_h, self.n_out_w = A.shape\n",
    "        return A.reshape(self.n_samples, -1)\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        return dA.reshape(self.n_samples, self.n_out_channels, self.n_out_h, self.n_out_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 7.\n",
    "class ActSigmoid:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return self.sigmoid(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        _sig = self.sigmoid(self.A)\n",
    "        return dZ * (1 - _sig)*_sig\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "class ActTanh:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A))**2)\n",
    "\n",
    "class ActSoftmax:\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Y):\n",
    "        self.loss = self.loss_func(Y)\n",
    "        return self.Z - Y\n",
    "    \n",
    "    def loss_func(self, Y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "\n",
    "class ActReLU:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.clip(A, 0, None)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
    "\n",
    "class ScratchConvNeuralNetrowkClassifier:\n",
    "    \n",
    "    def __init__(self, num_epoch=10, lr=0.01, batch_size=20, \n",
    "                 n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, \n",
    "                 verbose=True, Activater=ActTanh, Optimizer=AdaGrad):\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.batch_size = batch_size # バッチサイズ\n",
    "        self.n_features = n_features # 特徴量の数\n",
    "        # self.n_nodes1 = n_nodes1 # 1層目のノード数 # self.conv2d_3.n_out になる\n",
    "        self.n_nodes2 = n_nodes2 # 2層目のノード数\n",
    "        self.n_output = n_output # 出力のクラス数（3層目のノード数）\n",
    "        \n",
    "        self.Activater = Activater\n",
    "        if Activater == ActSigmoid or Activater == ActTanh:\n",
    "            self.Initializer = XavierInitializer\n",
    "        elif Activater == ActReLU:\n",
    "            self.Initializer = HeInitializer\n",
    "        else:\n",
    "            print(\"活性化関数が不適切\")\n",
    "        self.Optimizer = Optimizer\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        self.val_enable = False\n",
    "        if X_val is not None:\n",
    "            self.val_enable = True\n",
    "        \n",
    "        #optimizer = self.Optimizer(self.lr)\n",
    "        self.conv2d_3 = Conv2d_3(filter_size=[7, 7], initializer=SimpleInitializer(0.01), optimizer=self.Optimizer(self.lr), n_in_channels=1, n_out_channels=1, pa=[3, 3], st=[2, 2])\n",
    "        self.conv2d_3.n_out_h = out_size(X.shape[-2], self.conv2d_3.filter_size_h, self.conv2d_3.pa_h, self.conv2d_3.st_h)\n",
    "        self.conv2d_3.n_out_w = out_size(X.shape[-1], self.conv2d_3.filter_size_w, self.conv2d_3.pa_w, self.conv2d_3.st_w)\n",
    "        self.flatten = Flatten()\n",
    "        self.activation1 = self.Activater()\n",
    "        self.FC2 = FC(1*self.conv2d_3.n_out_h*self.conv2d_3.n_out_w, self.n_nodes2, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation2 = self.Activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation3 = ActSoftmax()\n",
    "        \n",
    "        self.loss = []\n",
    "        self.loss_epoch = [self.activation3.loss_func(y, self.forward_propagation(X))]\n",
    "        \n",
    "        for i in range(self.num_epoch):\n",
    "            time0 = time.time=()\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            self.iter = len(get_mini_batch)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                self.forward_propagation(mini_X)\n",
    "                self.back_propagation(mini_X, mini_y)\n",
    "                self.loss.append(self.activation3.loss)\n",
    "            self.loss_epoch.append(self.activation3.loss_func(y, self.forward_propagation(X)))\n",
    "            print(\"epoch[\", i+1, \"]:\", round(time.time()-time0, 2), \"(s)\", sep=\"\")\n",
    "            \n",
    "        if self.verbose:\n",
    "            self.learning_curve()\n",
    "            print()\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward_propagation(X), axis=1)\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        A1 = self.conv2d_3.forward(X)\n",
    "        A1 = self.flatten.forward(A1)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        return Z3\n",
    "    \n",
    "    def back_propagation(self, X, y_true):\n",
    "        dA3 = self.activation3.backward(y_true) #交差エントロピー誤差とソフトマックスを合わせている\n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        dA1 = self.flatten.backward(dA1)\n",
    "        dZ0 = self.conv2d_3.backward(dA1) #dZ0は使用しない\n",
    "        \n",
    "    def learning_curve(self):\n",
    "        plt.title(\"model_loss\")\n",
    "        plt.xlabel(\"num_epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(np.arange(1, self.num_epoch*self.iter+1), self.loss, label = \"train_loss\")\n",
    "        plt.plot(np.arange(0, self.num_epoch + 1)*self.iter, self.loss_epoch, label = \"epoch_loss\")\n",
    "        if self.val_enable:\n",
    "            plt.plot(np.arange(1, self.num_epoch + 1), self.val_loss, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        return \n",
    "        \n",
    "class FC:\n",
    "\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        A = X@self.W + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dZ = dA@self.W.T\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.X.T@dA\n",
    "        self.optimizer.update(self)\n",
    "        return dZ\n",
    "\n",
    "class XavierInitializer:\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(1 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "    \n",
    "class HeInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "\n",
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    print(\"accuracy =\", accuracy_score(y_true, y_pred))\n",
    "    print(\"precision =\", precision_score(y_true, y_pred, average='macro'))\n",
    "    print(\"recall =\", recall_score(y_true, y_pred, average='macro'))\n",
    "    print(\"f1 =\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-79d80ad5e8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                   \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                   verbose=True, Activater=ActReLU, Optimizer=AdaGrad)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscratch_cnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-ed3b9b7b91b7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch[\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"]:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "scratch_cnn1 = ScratchConvNeuralNetrowkClassifier(num_epoch=10, lr=0.01, batch_size=20, \n",
    "                                                  n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, \n",
    "                                                  verbose=True, Activater=ActReLU, Optimizer=AdaGrad)\n",
    "scratch_cnn1.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = scratch_cnn1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 8(Advance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 9(Advance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploblem 11(Advance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
