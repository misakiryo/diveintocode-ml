{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWlglCbe5HsH"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM4fLtUUAOGW"
   },
   "source": [
    "いくつかのアイデアとコードは、以前のカーネルと最後に準備したノートブックから引用しました。\n",
    "\n",
    "データ処理とチャンネル特徴のエンジニアリングを扱った後、モデリングの次のステップは、モデルアーキテクチャの準備とチューニングです。以前のノートブックでは、3つのチャンネルを持つ画像を作成する方法を提供していましたが、これは事前に学習されたモデルの使用を容易にするものです。\n",
    "\n",
    "セグメンテーションタスクでは、事前に学習させたモデルを最終的なアーキテクチャのエンコーダ部分として使用することができます。事前学習されたモデルを使用するには、いくつかの中間層から特徴を抽出する必要があります。これらの特徴は、後続の層や、エンコーダ部とデコーダ部の間のスキップ接続の基礎となります。\n",
    "\n",
    "ResNet50は4つのブロックで構成されており、それぞれのブロックが特徴抽出器として機能し、標準的なUNetアーキテクチャとの整合性を保つために、第1層が第5の抽出器として機能します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TelAwN3N2LXo",
    "outputId": "e5760c0b-86dc-4329-ddca-ba868ef83a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
      "\u001b[K     |████████████████████████████████| 109.3MB 48kB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 43.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 35.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (54.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
      "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1HyVlQI2YHs",
    "outputId": "54084ed6-6301-4a48-8c86-6dff3cc20ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\r",
      "\u001b[K     |█                               | 10kB 16.9MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 20kB 20.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 30kB 10.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 40kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 51kB 4.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 61kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 71kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 81kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 92kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 102kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 112kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 122kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 133kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 143kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 153kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 163kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 174kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 184kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 194kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 204kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 215kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 225kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 235kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 245kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 256kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 266kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 276kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 286kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 296kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 307kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 317kB 4.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uycAxyGIHZ-V",
    "outputId": "a20bb5d1-f7b7-4e84-be43-cfdbb7c3cbbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3sfeeoRJ5HsP"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B8NdUpMs5HsR"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oHeWOT2d5HsS"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v631ojkJ5HsV"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxtpZphD5HsX",
    "outputId": "17b7e1e5-cd43-4936-d1e5-6110d4875a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/saltparser/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/saltparser/sample_submission.csv')\n",
    "depth = pd.read_csv('/content/drive/MyDrive/saltparser/depths.csv')\n",
    "\n",
    "train_src = '/content/drive/MyDrive/unet/data/membrane/train'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK7ieRbB5HsY"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dOOADVi5Hsl",
    "outputId": "82252458-54d7-4ef9-a9ca-6d011efff52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/MyDrive/unet/data/membrane/train/image/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/MyDrive/unet/data/membrane/train/label/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "4NVu-NRu5Hsl",
    "outputId": "4d6bd91d-fcf5-4e94-9fdf-208d94e2ea6d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4498fa990>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAiNoDSm5Hsm"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MIjAo7vR5Hsn"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r__4GTjR5Hsn"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cxFe8p95Hsn",
    "outputId": "20f06ce2-9955-4535-ff18-1dfb0fe597e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23K_HxKA5Hso"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PUWmsKD85Hso"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxsmZHS45Hsu"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwdZErkiAeDC"
   },
   "source": [
    "ResNet50では、各ブロックの最後にプーリング層があるので、プーリングの直前に中間層から特徴量を抽出することができます。このようにして、第1層を追加抽出器として追加した場合、5つの層から特徴が抽出されることになります。デフォルトの入力サイズは(224, 224, 3)を想定しています。レイヤーは以下のようになります。\n",
    "\n",
    "\n",
    "留意点としては、ノートブックの同じTFセッションでモデルを作成するたびに、レイヤー名が変わるので、上記のレイヤー名はモデルの最初の作成に対応しています。セッションをリセットするには、K.clear_session()を呼んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a05yqocM5Hs4"
   },
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_83drm9yEPk",
    "outputId": "07459e81-d2f3-4239-c368-7db7305c5e7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 56, 56, 256)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 56, 56, 256)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 56, 56, 256)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 512)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 512)  0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 512)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 28, 28, 512)  0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 1024) 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 1024) 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 1024) 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 1024) 0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 1024) 0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 14, 14, 1024) 0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 2048)   0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 2048)   0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 7, 7, 2048)   0           add_38[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53slaUd_zqeB",
    "outputId": "582e239d-2281-4ec0-86f0-17d87191f38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRvE6n4Z5Hs5"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RJJ3ErN75Hs5"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXDow5aD5Hs6"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ydS9uMe55HtJ"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    base_model = VGG16(\n",
    "        include_top=True, \n",
    "        weights='imagenet', \n",
    "        input_tensor=None, \n",
    "        input_shape=None)\n",
    "    \n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4CH6ehI5HtP"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8v-SPRL5HtS",
    "outputId": "de22755d-87c6-48e7-e44d-b5ba3418b69b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 22s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-13-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,611,201\n",
      "Trainable params: 22,609,089\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuLp0gsc5HtT"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDPo6eq55HtU",
    "outputId": "5e6a781d-cb6c-48a4-dc33-387112eeb05b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,677,489\n",
      "Trainable params: 28,672,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 5150s 2s/step - loss: 0.9023 - my_iou_metric: 0.1786 - val_loss: 1.1345 - val_my_iou_metric: 0.1786\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.17863, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 5171s 2s/step - loss: 0.6788 - my_iou_metric: 0.3088 - val_loss: 1.2133 - val_my_iou_metric: 0.2182\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.17863 to 0.21825, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kerLr1Oc5HtV"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xfuU9T9t5HtZ"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gpTAWMN5Htd"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3m2xrqhp5Htd"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gPrmLb45Hte",
    "outputId": "eefe8140-66e7-4af0-94ff-7e187bd1d84c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:51<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "2ljBM4cL5Hte",
    "outputId": "1efc1b98-afaf-4083-eae5-61001eb296f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3084 at threshold: 0.480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.297175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.008297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.287875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.299250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.304187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.308375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.297175\n",
       "std     0.204939   0.008297\n",
       "min     0.200000   0.285250\n",
       "25%     0.370000   0.287875\n",
       "50%     0.540000   0.299250\n",
       "75%     0.710000   0.304187\n",
       "max     0.880000   0.308375"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "7Kq6nRQd5Htk",
    "outputId": "50d9192f-23ca-4a73-a6df-0a52923b5b97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc439c1af50>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9bn48c+TyUY2sgdIgIQtEJBFEgQRBAuIG6jtVWztT2/Valuvtlpre/V6W1vvr9X+2tpW22utVbuo1VaNSxVEUVC2IAlL2AIESCIhJITsy2S+vz9mggGyTJLJnBPmeb9eeTFz5pwzz4TMPHO+y/MVYwxKKaUCV5DVASillLKWJgKllApwmgiUUirAaSJQSqkAp4lAKaUCXLDVAfRGYmKiSU9PtzoMpZQaVLZs2XLcGJPU1eODKhGkp6eTl5dndRhKKTWoiMih7h7XpiGllApwmgiUUirAaSJQSqkAN6j6CJRSytdaW1spKSmhqanJ6lD6LTw8nLS0NEJCQnp1nCYCpVRAKykpITo6mvT0dETE6nD6zBhDZWUlJSUlZGRk9OpYbRpSSgW0pqYmEhISBnUSABAREhIS+nRlo4lAKRXwBnsSaNfX16FNQ+qcUdfspPREI2XVjZRUN2KM4cYLRhMUdG68yZUaKJoI1KBT1+zkpc1HOFxZT2l1I6XVTZSeaKCmyXnWvkOHhLB8eqoFUSrlvQsvvJBPPvnEsufXRKAGlabWNr727GY2HawiOjyY1NghpMYOISc9jhGe2+3/3vynTfxi1V4uP284IQ5tBVX2ZWUSAE0EahBpbXPxrb9+yubiKh5fMb3Hb/r3XZrJLc/l8XJeCV++YJSfolSq96Kioqirq8MYw/e+9z3+9a9/ISI8+OCDXH/99axZs4af//znvPnmmwDceeedZGdnc/PNN/vk+TURqEHB5TJ89+UCVu8+xk+unuJVc88lE5M5f1Qsv169j2vPTyU8xOGHSNVg9qM3dlJYVuPTc2aNiOG/r5rs1b7//Oc/yc/Pp6CggOPHj5OTk8P8+fN9Gk9n9HpZ2Z4xhh++sZPX88u479JMbpw92qvjRIT7Lp3I0Zom/rKh25pb3T53TVNrn45VqrfWrVvHDTfcgMPhICUlhYsvvpjNmzcP+PPqFYGyvV+u2svz6w9x+/wxfHPB2F4dO2dsAvPGJ/LEB0VcnzOS6PDezbj8z1d38OrWEl64bTYzRsX16lg1+Hj7zd3fgoODcblcp+77eha0XhEoW3t67QF+/X4R12eP5PuXTezTOOnvLsnkREMrz6wr7tVxr2wp4YVNhzEGbnt+C2XVjb1+bqV6Y968ebz00ku0tbVRUVHBRx99xKxZsxg9ejSFhYU0NzdTXV3N6tWrffq8mgiUbb2cd4SfvLWLy88bxv9ce16fJ8tMGxnLpZNTeHrtAU7Ut3h1zO6jNTz42nZmj4nn9Tvn0tzaxi3P5VHffPYQVaV85ZprrmHq1KlMmzaNSy65hEcffZRhw4YxcuRIrrvuOqZMmcJ1113HjBkzfPq8Yozx6QkHUnZ2ttGFaQLDOzuO8s2/bmHuuESevimbsOD+dfTuLa/l0l99xNfnj+EHl03qdt+6ZifLfruO2iYnb911EcnR4azZc4yvPbuZRZNS+P2NM3WS2jlk165dTJrU/d/EYNLZ6xGRLcaY7K6O0SsCZTsfFx3nrhe2Mm1kLL+/cWa/kwDAhJRorpmeynOfFFNe03X7qjGG7/9jG8XH6/n1ihkkR4cDsCAzmf+6MouVheU8tnJPv+NRyk40EShbOVLVwG3P5zEmKZJnb55FZJjvxjN8e9EEnG2G375f1OU+f9lwiDe3fca9SzKZMzbhtMduvjCdL18wit+t2c8rW0p8FpdSVtNEoGxlZ9lJGlra+OkXpzI0oncjfHoyKiGCFbNG8sKmwxyubDjr8W0l1fz4zV0szEziGxefPTpJRPjRsslcODaBH/xzG5uLq3wan7LOYGoi705fX4cmAmUr7fWCEiJDB+T8/3HJeBxBwq9W7z1t+8mGVr75109Jig7jF9dN77IPIMQRxJNfOZ+0uAhu//MWjlSdnVDU4BIeHk5lZeWgTwbt6xGEh4f3+lidR6BspdaTCGJ6Od7fWykx4dx8YTpPrT3AHRePZUJKNC6X4d6X8ymvaeLlOy4krockFBsRyh9vyubqJz7mluc2849vXNjr+QnKPtLS0igpKaGiosLqUPqtfYWy3tJEoGylzpMIIsMGrhzEHReP5a8bD/OLlXv5/Vdn8tTaA7y36xg/vCqL6SNjvTrHmKQofnfjTP7PM5u464WtPH1TDg4dSTQohYSE9HpFr3ONNg0pW6ltaiUi1EHwAFYLjYsM5bZ5Y3hn51GeXnuAx97dwxXnDeemC9N7dZ654xL50bLJfLCnggde3U5FbfPABKzUANMrAmUrtU1OosMH/s/ylnkZPLe+mJ+8tYuMxEh++sW+TVi7cfZoDlXW84e1B3l5SwkXjUvkmhmpLJmcQkSovr3U4KB/qcpWaptb/dLeHhUWzL1LJvDYu3t48ivn9+s5H7gii3/LHslrW0t5Pb+Mb7+UT0SogyVZKVw9I5WLxiUO6BWOUv2lM4uVrXz1jxupbXLy2rfm+uX5nG0un35Iu1yGvEMneHVrKW9tK6OmyUliVChXTh3BkqwURsZHMGxouC6Uo/yqp5nFekWgbMVfTUPtfP1NPShImJURz6yMeH64LIs1eyp4bWspf9t4mGc/KXbvIzAsJty9klrc5yuqpcYOYXJqzKnZzEr5iyYCZSu1Ta2kxg6xOgyfCAt2cOnkYVw6eRgnG1spOFJNWXUjZdWNlHj+/fTwCd7a9hlOl/vKPDV2CGu/t1BrGSm/0kSgbMXfVwT+MnRICPMnJHX6WJvLcLyumVe3lvLTf+1me+lJpnk5jFUpX9CGSmUr52oi6I4jSEiJCWdFzkgcQcLKwqNWh6QCjCYCZRutbS4aW9uICgvMWbqxEaHMSo9nVWG51aGoAKOJQNlG+6IvgXZF0NGSySnsLa+j+Hi91aGoAKKJQNlGe52hQE4Ei7NSAPSqQPmVV4lARJaKyB4RKRKR73fy+B0isl1E8kVknYhkdXjsB57j9ojIpR22F3c4RicHKGqaWgECuoBbWlwEWcNjtJ9A+VWPiUBEHMATwGVAFnBDxw96j78ZY84zxkwHHgV+4Tk2C1gBTAaWAk96ztduoTFmencTHVTg+LzyaOBeEYD7qmDLoRNU1mntIuUf3lwRzAKKjDEHjDEtwIvA8o47GGNqOtyNBNqnKy8HXjTGNBtjDgJFnvMpdZb2RBCliQCXgdW7j1kdigoQ3iSCVOBIh/slnm2nEZFvich+3FcEd3lxrAFWisgWEfl6V08uIl8XkTwRyTsX6oWrrtU1a9MQwOQRMaTGDmHlTu0nUP7hs85iY8wTxpixwP3Ag14ccpEx5nzcTU7fEpH5XZz3KWNMtjEmOymp8wk56tygncVuIsLirBTWFVXQ2NJmdTgqAHiTCEqBkR3up3m2deVF4OqejjXGtP97DHgVbTIKeJoIPrckK4WmVhcf7dOr4MHK2ebi9fxSnG0uq0PpkTeJYDMwXkQyRCQUd+dvbscdRGR8h7tXAPs8t3OBFSISJiIZwHhgk4hEiki059hIYAmwo38vRQ12NU2thAYHERY8cKuTDRY5GfHEhAfrMNJBLLegjLtfzB8U/4c9fvUyxjhF5E7gXcABPGOM2SkiDwN5xphc4E4RWQS0AieAmzzH7hSRvwOFgBP4ljGmTURSgFc9C4EE4x519M4AvD41iNQ1OYkO06sBgBBHEJdMTGb1rnKfl8pW/pFbUAbAJ/sruey84RZH0z2v3nXGmLeBt8/Y9lCH23d3c+wjwCNnbDsATOtVpOqcF4h1hrqzZPIwXssvY8uhE1wwJsHqcFQvVNY1s3bfcQDWH6i0OJqe6dcMZRu1Tf5ZnWywmD8hiVBHECsHQdOCOt3bO47S5jJcMyOVomN1HKttsjqkbmkiULahVwSniwoLZu64BFYVljOYVhJU8EZ+GeOTo7j5wnQANhyosjagHmgiULahieBsi7OGcbiqgT3ltVaHorxUWt3IpuIqlk8fweQRMUSHBbN+v72bhzQRKNuoa3YGbAnqriyalAzAKp1cNmi86ekkvmraCIIdQczKiGeDzfsJNBEo26hpatUrgjMkx4QzY1RswPcTtDhdXPWbdadG4tjZ6/llTB8Zy+iESADmjE3g4PF6jp60bz+BJgJlCy6Xoa7ZGfAF5zqzOCuF7aUnKatutDoUy2w8WMn20pO8tc3eiaDoWB2Fn9WwbNqIU9tme0Z8rT9w3KqweqSJQNlCfYsTY7TOUGeWZA0D4L1dgXtV0D4pa8uhE7buOM8tKCNI4Mqpn88byBoew9AhIbbuJ9BEoGxBy0t0bVxyFGMSIwfFDNWBYIxhVWE5ocFBHK9robiyweqQOmWMITe/lDljE0iOCT+1PShIuCAj3tbzCTQRKFuoa9YS1N1ZnJXC+v2VnGxstToUv9tRWsNnJ5v497npAGwutudQzO2lJymubDitWajdnLEJHKlqpOSEPZOYJgJlC7W6Olm3lkxOwekyrNkTeGsUrCw8SpDA1+eNITYihC3FJ6wOqVO5+WWEOISlk88uJzFnrKefwKbNQ5oIlC3UaNNQt6aPjCMxKjQgm4dWFZaTnR5PQlQY2aPj2HzIflcEbS7DG9vKWJCZzNCIs7/MTEiOJj4y1LbNQ5oIlC3oMpXdcwQJiyalsGZPBc3OwFmj4HBlA7uP1rIkKwWAmaPjOVBRb7tlPDcdrKK8prnTZiFw9xPMHhPPhv2Vtuzs1kSgbKG9aUgnlHVtcVYKdc1O25cr8KWVhUeBz0dO5aTHAe7RQ3aSW1BKRKiDRZNSutxnzpgEyk42cbjKfv0EmgiULdRp01CP5o5LZEiIg5U7j1odit+sKixn4rBoRiVEADAldSihjiBbJYIWp4u3tx9lSVYKQ0K7XkvDzv0EmgiULdQ2OXEECRHdvJECXXiIgy9MSuYfn5awo/Sk1eEMuKr6FjYXV7E46/Nv2eEhDqamDbXVyKG1+yo42djKsumdNwu1G5sURVJ0mC37CTQRKFuobWolKiwYz2JFqgsPXZVFfEQotz6Xx7Ea+5Ys8IX3dx/DZT5vFmo3Mz2O7aUnaWq1R1/J6/llxEWEMG9892uqiwizxySw3ob9BJoIlC1o5VHvJEeH8/RNOdQ0tXLb83m2+TAcCCt3HmX40HCmpMactj1ndDytbYZtJdZfFTW0OFlVWM5l5w0nxItV5OaMSeBYbTMHjtf7ITrvaSJQtlDT5CRKl6n0StaIGH51/XS2lZ7k3pcLbPft0hcaW9r4aF8FiyalnHWVOHO0u8PYDs1D7+06RmNrG8u7GC10Jrv2E2giULZQ19xKjE4m89qSycO4f+lE3tr2Gb96b5/V4fjcuqLjNLW6WDL57FE4cZGhjEuOskWHcW5+KcOHhpOTHu/V/ukJEQyLCbddP4EmAmUL2jTUe7fPH8MXz0/j8dX7BkV55t5YVXiU6LBgLsjofK3mnPQ48oqrcLmsuxqqbmjhw70VXDl1OEFB3vVtiQhzxiaw8YC9+gk0EShb0ETQeyLC/1w7hZz0OO57uYD8I9VWh+QTbS7D6l3HWDgxmdDgzj+iZo6Op6bJSVFFnZ+j+9y/dhyltc2wfHpqr46bMyaB43Ut7DtmXexn0kSgbEEXru+bsGAHv79xJknRYdz2fN45sWbBp4dPUFnfctqw0TO1Tyyzsp8gN7+MMYmRTB4R0/POHdixn0ATgbKcMYbaJqdWHu2jhKgwnrk5h8aWNm59Lo+GFqfVIfXLqsJyQhzCgsyuh2OOio8gMSqMPIsK0B2raWLDwUqWTR/R6yHPI+MjSI0doolAqY6anS6cLqNNQ/0wISWa33x5BruP1vCdl/ItbTvvD2MMK3ceZc7YxG6vEEXE3U9gUQG6dUXHMYZur1q6M2dsAhsOVtrm/0kTgbJcjZag9omFmck8cEUW7+4s5/HVg3MkUdGxOoorG7z6gM1Oj+dIVSPlFkys23igiqFDQpg0rHfNQu1mj0mguqGV3UdrfRxZ32giUJbTyqO+87W56SzJSuG59cW02eTbZm+s9JTZXtxN8bZ22Z75BFY0D208WElOerzXo4XOdKqfwCbDSDURKMvpMpW+IyJcNW0E1Q2tg3IU0crCcqalDWXY0PAe980aEcOQEIffO4zLa5oormxg9hjv5g50JjV2CKPiI2zTT6CJQFlOS1D71vzxSQQJg241s/KaJgqOVLNk8rCedwZCHEFMHxnbq34CYwyv55f2a8nPDZ5v8V3NcfDWnDEJbDxYaYsrN00EynJagtq3hkaEMHN0HB8MskTQvvpabzpgc9LjKCyrObXmdU9eyy/l7hfzee6T4r6ECMDGg1VEhwWT1ctho2eaMzaB2iYnhWU1/TqPL2giUJbTpiHfW5CZzI7Smn5VKD1S1eDXCqerCstJT4hgfHKU18fMTI/HZSD/cM/NYLVNrfzP27sB+pUkNx6oJDs9Dkcf+wfafd5PcLxf5/EFTQTKcjpqyPcWZiYDsGZvRZ+Od7kMK57awL0vF/gyrC7VNrXyyf7jLM46u8hcd84fFUuQ4FXz0K/e28fxumYWTUoh/0g1VfUtvY6zoraZ/RX1XDCmf81CACkx4YxJjLRFP4EmAmW59isCrT7qO5OGR5MSE9bnfoK8QycorW5kw4HKU304A+nDvRW0thkWZ3nXP9AuOjyEicNiehw5tPtoDc9+UsyKnFH8xyXjMAY+6kOS3HTQnXAuyOh7R3FHs8cmsLn4BM42l0/O11eaCJTlapucRIY6+n2prT4nIizMTGbt3uO09uFD5vX8UgBa2wwfFw38N9aVO8uJjww9VWK6N7LT49h6uOsPU2MMD72+k+jwYL53aSbnpQ4lITK0T81DGw9WEhHqYErq0F4f25m5YxOpa3aytsja5iFNBMpydc1aZ2ggLMhMprbZ2etyza1tLt7e/hmXTRlGdFjwgI8+ana28cGeY3xhYnKfvgxkp8dT39LW5eSs3IIyNh2s4r5LM4mLDCUoSLg4M4kP91b0esTOxgNVzBwd59UiNN5YlJVMauwQfrlqr6XVSL16NSKyVET2iEiRiHy/k8fvEJHtIpIvIutEJKvDYz/wHLdHRC719pwqcGjl0YExd1wCIQ5hzZ7eNYGsKzrOiYZWrj0/jXkTElmzp2JAP6TW7KmgtsnJFVOH9+n47G4WqqltauWRt3YxNW0oK3JGndq+MDO513Mtqupb2FNey2wf9A+0Cwt2cPei8WwrOcm7O8t9dt7e6jERiIgDeAK4DMgCbuj4Qe/xN2PMecaY6cCjwC88x2YBK4DJwFLgSRFxeHlOFSA0EQyM6PAQctLje/2NPje/jJjwYOZPSGRBZjJHa5oGtBRCbkEZ8ZGhzB2X2KfjR8QOITV2CHmdXPk8/t4+KuqaeXj5lNOuNvoy18LX/QPtrp2RypikSP7fyj2WzSnw5opgFlBkjDlgjGkBXgSWd9zBGNNxIGwk0P5qlgMvGmOajTEHgSLP+Xo8pwocWoJ64CzMTGb30Vqvy1M3trSxcudRLj9vOGHBDhZMcFcAHag5CXXNTlbvKucKL9f87crM0e6Fajpeuewtr+VPnxRzffZIpo+MPW3/vsy12HCgkvCQIKamxfa8cy8EO4K4d3Em+47Vneqb8TdvfvOpwJEO90s8204jIt8Skf24rwju6uFYr87pOe/XRSRPRPIqKvo2FE7Zm5agHjgLJ7o/yL1tHnp/9zHqW9pY5lmDNzkmnMkjYlize2Dee6sKj9LU6mLZdO/W/O1KTnoc5TXNlJxwJzx3B/EOosKC+d7SiZ0ec2quRa13cyU2HnT3D3S1WE5/XDZlGJNHxPDL9/bS4vT/CCKfvSJjzBPGmLHA/cCDPjzvU8aYbGNMdlJS1/XJ1eBV2+zUgnMDZGxSFGlxQ7z+5vt6finJ0WGnjZNfmJnMlsMnONng+2GkufllpMYOYeao3o8W6ijbs2Zw+3yCN7Z9xoYDVXz30kziI0M7PaZ9rsWHXiTJkw2t7D5a0++yEl0JChK+e2kmR6oaeSnvSM8H+Pr5vdinFBjZ4X6aZ1tXXgSu7uHY3p5TncO0aWjgtA8j/bjoOM3Otm73PdnYypo9FVw5dcRp7ekLJybR5jKsLfLtVUFVfQtr9x3nymner/nblQkp0USHBbO5+AR1zU4eeauQKakxfHnWqC6P+XyuRc+va1NxFcb4vn+gowUTkshJj+M3q/fR2NL9/5WveZMINgPjRSRDREJxd/7mdtxBRMZ3uHsF0F4MPRdYISJhIpIBjAc2eXNOFRha21w0tbqI1slkA2bhxCQaWtrYfLD7YaTv7jxKS9vZzTTTR8YRGxHCBz5uHnp7+2c4XeZUM1R/OIKE80fHsaX4BL9evY/ymrM7iM/UniQ/2lfR41yLjQcqCQ0OYtpI3/YPnBnPfZdO5FhtM8+vLx6w5+lMj4nAGOME7gTeBXYBfzfG7BSRh0VkmWe3O0Vkp4jkA/cAN3mO3Qn8HSgE3gG+ZYxp6+qcPn5tahA4NatYm4YGzJwxiYQGB/XYPJSbX8bohAimpZ0+WcoRJMwfn8SHe4/5dEWt3IIyxiVHkTW8f8Xb2mWPjmNPeS3PrDvIddlpnO9Fc9OCzGRqm5x82sNci40Hq5gxMpbwEIdPYu3KrIx4Lp6QxO8+3H+q9Io/eNVHYIx52xgzwRgz1hjziGfbQ8aYXM/tu40xk40x040xCzt+qBtjHvEcl2mM+Vd351SBp1brDA24IaEO5oxJ6DYRHKtt4pP9x1k2rfM1eBdOTOJ4XQs7yk76JKay6kY2Hazq8vn6or2fICLUwf1ddBCfqX2uxQfdNA/VNLWys+ykT+oLeeO+SzOpbmjl6bUH/fJ8oDOLlcW08qh/LMhM4kBFPYcq6zt9/O1tn+EydNlMM398EiL4rHnozW1lQNfP1xfTR8aSkRjJf12ZRUJUmFfHeDPXYkvxCVwGZg9g/0BHU1KHcsV5w/nj2gNU1jX75Tk1EShLaSLwj1PVSLv45vt6QRmThscwPiW608cTosKYlhbrs/kEuQVlTEsbSnpipE/OB+4rnw++u4B/yx7Z884d9DTXYsPBSkIcwox+jmzqje8snkBjaxu/W7PfL8+niUBZqr1pKEabhgZUemIkGYmRnX6QH65sYOvh6h6/nS/MTKagpLrf31L3V9Sxo7SGq3x4NdAfPc212HigimlpsQwJHdj+gY7GJUfxxfPTeH7DIT476d1kwP7QRKAspSWo/WdBZhLr91eeNTTxDU8zzVXTuq/1s3Bikrt8877+NQ/l5pchgm0SQXdzLeqbnWwvPckF/VifuK/uXjQeYwy/Xl004M+liUBZqn2JQW0aGngLM5NpdrpOrbnbLje/jOzRcaTFRXR7/JQRQ0mMCu1XP4ExhjcKypidkUBKTM8L1PtDd3Mtthw6QZvLDNhEsu6kxUXwlQtG8/e8IxQf77xvx1c0EShL6agh/5mVEc+QEMdp33x3H61hT3mtVyUegoKEiyck96l8c7sdpTUcOF7f75ISvtbVXIuNBytxBEmf1knwhW8uHEuoI4hfvrd3QJ9HE4GyVG2Tk7DgoAGp36JOFx7iYO449zDS9uJsufllOIKEy8/zrgT0wolJnGxsJf9I79Y4aJdbUEqIQ7hsSu9WIhtoXc212HCgivNShxJpUdNlcnQ4/z43ndyCMnZ9NnCL3Ou7T1mqpsmpVwN+tCAzmSNVjRw4Xu9uptlWxtxxiSR6Odxy3rgkHEHSp+Yhl8vwRsFnXDwhidiIzuv/WGVIqIPZZ8y1aGxpY1tJtSX9Ax3dPn8sD1w+iQwfjrA6kyYCZSl3nSHtH/CXBZmestK7j7H1SDVHqhp7NZZ/aEQIM0f1rnxzu03FVRytabJNJ/GZFp4x1+LTwydobTPMtqB/oKOhESHcOm/MgM5q1kSgLFXXrIvS+FNaXAQTUqJYs6eC3PwyQoODuHRySq/OsWBiEjvLaiiv8a58c7vcgjKGhDhYnNW75/OXM+dabDxQSZC410Q+12kiUJbS1cn8b2FmMhsPVvJGQRlfmJjc66a53pRvbtfidK+DvDgrhYhQe/5/nznXYsPBKqakDg2IpktNBMpStU2tRIed+280O1mQmUxrm6GyvqVPJR4mDotmWEx4r5qH1hVVUN3QynKbjRY6U/tci5Oe9YwHsuy0nWgiUJbSKwL/y06PIyosmOiwYBZOTO718SLCwolJrN13vMfyze1y88sYOiSEeePtvbhU+1yLJz8sosXpsmT+gBU0EShL6TKV/hfiCOKbC8dy1xfG97kDckFmMnXNTvKKex5G2tjSxsrCci4/b5jthwm3z7V49uNiRCBHrwiUGlgul/F0FmvTkL99c8E4bps/ps/Hzx2XSIhDuq3a2e69XeU0tLSxbFqny5LbSvtci2ani0nDYhg6JDD+NjURKMvUtbjLS+h6xYNPVFgwszLiu+0naHMZCstq+POGQ6TEhDFrkHy7XuDpDLd6/oA/6TtQWUZLUA9uCzOT+clbuyg50UBaXATNzja2l5xkU3EVmw9WkXfoxKn/4+8tzex22Ug7WZyVwuOr97F0sr1mPw8kfQcqy2idocFtgScRPPT6TuqanRQcqabZ6e48HpsUyZVTh5OTHs+sjPgeC9rZSUpMOJsfWGR1GH6liUBZRktQD25jkyIZnxzFh3srmDwihhtnjyYnPZ6c9DivVwhT9qDvQGWZOm0aGtREhNe+NReDJvPBTv/3lGVqtGlo0LOqKqfyLR01pCzT3jSko4aUspYmAmWZz0cN6RWBUlbSRKAsU9vUiiNICA/RP0OlrKTvQGWZ9hLUIoNjfLlS5ypNBMoyWnBOKXvQRKAsoyWolbIHTQTKMjVaeVQpW9BEoCxT2+TUoaNK2YAmAmWZuuZWHTqqlA1oIlCW0c5ipexBE4GyhDFGE4FSNqGJQFmisbWNNpchSkcNKWU5rxKBiCwVkT0iUiQi3+/k8XtEpFBEtonIahEZ3eGxn4nIDmXlCncAABZISURBVM/P9R22PysiB0Uk3/Mz3TcvSQ0GuiiNUvbRYyIQEQfwBHAZkAXcICJZZ+y2Fcg2xkwFXgEe9Rx7BXA+MB24APiuiMR0OO4+Y8x0z09+v1+NGjQ0EShlH95cEcwCiowxB4wxLcCLwPKOOxhjPjDGNHjubgDSPLezgI+MMU5jTD2wDVjqm9DVYNa+OlmMjhpSynLeJIJU4EiH+yWebV25BfiX53YBsFREIkQkEVgIjOyw7yOe5qRfioguaRRA9IpAKfvwaWexiNwIZAOPARhjVgJvA58ALwDrgTbP7j8AJgI5QDxwfxfn/LqI5IlIXkVFhS/DVRY6tUylJgKlLOdNIijl9G/xaZ5tpxGRRcADwDJjTHP7dmPMI54+gMWAAHs92z8zbs3An3A3QZ3FGPOUMSbbGJOdlJTk7etSNqcL1ytlH94kgs3AeBHJEJFQYAWQ23EHEZkB/C/uJHCsw3aHiCR4bk8FpgIrPfeHe/4V4GpgR/9fjhos6pq1aUgpu+jxXWiMcYrIncC7gAN4xhizU0QeBvKMMbm4m4KigJc9teUPG2OWASHAWs+2GuBGY4zTc+q/ikgS7quEfOAO3740ZWc1TU5EICpUE4FSVvPqXWiMeRt3W3/HbQ91uL2oi+OacI8c6uyxS7wPU51raptaiQoNJihIF6VRymo6s1hZolZLUCtlG5oIlCVqm1q1f0Apm9BEoCzhXq9YRwwpZQeaCJQltPKoUvahiUBZwp0I9IpAKTvQRKAsUdvUSlSYXhEoZQeaCJQlanS9YqVsQxOB8rtmZxstTpf2EShlE5oIlN/Vnao8qn0EStmBJgLld1qCWil70USg/O5UCWrtLFbKFjQRKL+rbdYS1ErZiSYC5XfaNKSUvWgiUH7Xngh0vWKl7EETgfK79tXJtPqoUvagiUD5nTYNKWUvmgiU39U1OwkPCSLEoX9+StmBvhOV37nXItD+AaXsQhOB8rsaLUGtlK1oIlB+V9vkJFonkyllG5oIlN9p05BS9qKJQPldnTYNKWUrmgiU3+kylUrZiyYC5XfaNKSUvWgiUH7V5jLUt7Rp5VGlbEQTgfKrOp1VrJTtaCJQftVegloLzillH5oIlF9pnSGl7EcTgfKrWl2vWCnb0USg/EpLUCtlP5oIlF9p05BS9qOJQPlVbbMmAqXsRhOB8qv2piEdNaSUfWgiUH5V2+QkxCGEBeufnlJ24dW7UUSWisgeESkSke938vg9IlIoIttEZLWIjO7w2M9EZIfn5/oO2zNEZKPnnC+JSKhvXpKys9qmVqLCghERq0NRSnn0mAhExAE8AVwGZAE3iEjWGbttBbKNMVOBV4BHPcdeAZwPTAcuAL4rIjGeY34G/NIYMw44AdzS/5ej7M5dcE6bhZSyE2+uCGYBRcaYA8aYFuBFYHnHHYwxHxhjGjx3NwBpnttZwEfGGKcxph7YBiwV99fBS3AnDYDngKv791LUYKAlqJWyH28SQSpwpMP9Es+2rtwC/MtzuwD3B3+EiCQCC4GRQAJQbYxx9nROEfm6iOSJSF5FRYUX4So70xLUStmPT9+RInIjkA1cDGCMWSkiOcAnQAWwHmjrzTmNMU8BTwFkZ2cbX8ar/K+mqZWR8RFWh6GU6sCbK4JS3N/i26V5tp1GRBYBDwDLjDHN7duNMY8YY6YbYxYDAuwFKoFYEQnu7pzq3KPrFStlP94kgs3AeM8on1BgBZDbcQcRmQH8L+4kcKzDdoeIJHhuTwWmAiuNMQb4APiSZ9ebgNf7+2KU/bkXpdFEoJSd9PiONMY4ReRO4F3AATxjjNkpIg8DecaYXOAxIAp42TMs8LAxZhkQAqz1bKsBbuzQL3A/8KKI/AT3qKM/+valKbsxxlDXrKOGlLIbr76aGWPeBt4+Y9tDHW4v6uK4Jtwjhzp77ADuEUkqQDS0tOEyWl5CKbvR6Z3Kb7QEtVL2pIlA+Y2WoFbKnjQRKL/ZW14HaNOQUnajiUD5xZo9x7jn7/mMT44iJz3e6nCUUh1oIlAD7p0dR7nt+TzGJUfx0u1ziNJ5BErZir4j1YB6bWsp975cwLS0ofzp32cxdIh2FCtlN5oI1IB5YdNh/vPV7czOSODpm7KJ1CsBpWxJ35lqQPxx3UF+/GYhCzOT+N2NMwkPcVgdklKqC5oIVI+q6lt4e/tnpMYOYWZ6XI/LTP72/X38fOVeLpsyjMdXzCBUVyNTytY0EaguHT3ZxB/WHuBvGw/T2OouGisCE4fFMCs9jlkZCeRkxJEcHQ64S0g89u4enlyzn2tnpPLol6YS7NAkoJTdaSJQZzlUWc/vP9zPK1tKcBlYPm0Et8zL4GRjK5sPnmBTcSV/zyvhufWHAEhPiCAnPR6ny/Dq1lK+csEofrx8CkFBuhylUoOBJgJ1yp6jtTy5pog3CsoIdgRxfc5Ibp8/9rT1Ay4cmwiMp7XNxc6yGjYfrGLjwSpW7SqnuqGVWy/K4IErJumaxEoNIpoIFNtKqvnN+0WsKiwnItTBrfPGcOtFGSTHhHd5TIgjiOkjY5k+Mpbb5o/B5TKcbGwlLjLUj5ErpXxBE0GA21l2kmue/ISosGC+vWg8N1+YTmxE7z/Mg4JEk4BSg5QmAgu0uQwOG7SfG2N45K1dxIQH8/69C/SDXKkApUM6/Kyu2cmSX37It1/cistl7RLM7+8+xif7K7n7C+M1CSgVwPSKwM8ee2c3+yvq2V9Rz8j4CO5dkmlJHK1tLv7n7V2MSYzkK7NHWxKDUsoeNBH40ZZDVTy/4RA3X5hOY0sbv3m/iHHJUSyfnur3WF7cdJj9FfU89dWZhOhYf6UCmiYCP2l2tnH/P7YzYugQ7rs0kxBHEMWV9dz3yjbS4iKYOTrOb7HUNLXyy/f2cUFGPIuzUvz2vEope9Kvgn7yxPtFFB2r45FrphAZFkxocBC/v3Emw4eGc/uf8yg50eC3WJ78YD9V9S08eEWWjvdXSmki8IfdR2t4cs1+rpmRyoLM5FPb4yJD+eNN2TQ7Xdz6XB51zc4Bj+VIVQPPfHyQa2ekcl7a0AF/PqWU/WkiGGBtLsP9/9hOzJAQ/uvKrLMeH5cczRNfPp99x+r49ov5tA3wSKLH3t2DAN+91JpOaqWU/WgiGGDPflJMwZFq/vuqLOK7GKI5f0ISD12ZxXu7ynn0nd0DFkv+kWpyC8q4bd4YRsQOGbDnUUoNLtpZPICOVDXw83f3cMnEZJZNG9HtvjddmE7RsTr+96MDjE2O4rrskT6NxRjDT94sJDEqjDsWjPXpuZVSg5teEQwQYwz/+ep2HEHCT66e4lWn7ENXZXHRuEQeeHU7Gw9U+jSed3YcJe/QCe5ZPEHXDFZKnUYTgcfe8lr2ldf67Hz/+LSUtfuOc//STK+bYUIcQTzx5fMZGR/BHX/ZwqHKep/E0uJ08dN3djMhJYrrstN8ck6l1LlDEwHwz09LuPLX61j2249Zt+94v89XUdvMj98sJCc9jq9c0LtZu0MjQvjjTTkY4IanNnDweP+TwfPrizlU2cB/Xj5JF4pRSp0loD8VXC7Dz97ZzT1/L2Dm6DhGJ0Twtec2815heb/O+8M3dtLY0sb/vXZqnxZnyUiM5G+3zqbZ6eLffr+ePUf7fqVS3dDCb94vYt74xNOGriqlVLuATQT1zU7u+MsWfrdmP1++YBTP3zKLF26bzcRh0dzxly28ua2sT+ddVVjOW9s+464vjGNcclSf48saEcNLt8/GEQQrnlrP9pKTfTrPr1cXUdvUygNXTOpzLEqpc1tAJoLS6ka+9Pv1vLernB9elcUjV08hxBFEXGQof731AmaMiuWuF7byct4Rr8/Z7GzjyTVF3PXCViYOi+b2i/s/MmdccjQv334hkWHBfPkPG8grrvL62OqGFh58bTt/+uQg12WPZOKwmH7Ho5Q6NwVcIvj08AmW//ZjSqoaeObmHG6em3HaiJ7o8BCe+9os5o5L5L5XtvHn9cU9nvPDvRVc9qu1PPrOHuaNT+RP/57js0JuoxIi+Pvtc0iKDuOrf9zEx0Xd92G4XIYXNh1m4c/X8LeNh7lpTnqnE9mUUqqdGGNtTfzeyM7ONnl5eX0+/vX8Uu57ZRvDYsJ55uZsxiVHd7lvU2sbd/5tK+/tKucHl03s9Bt+yYkGfvxmIe/uLCcjMZL/viprwNrhK2qbufHpjRysrOd3XzmfL0w6u1hcwZFqHnp9BwUlJ8lJj+Ph5VOYNFyvBJQKdCKyxRiT3eXjgZAIXC7DL1bt5bcfFHFBRjy/v3GmVwuxtLa5+M5L+by57TPu+sJ4vrNoPCJCU2sbf/joAE+sKUIQ7rxkHLfOyyAs2NGXl+W1E/Ut3PSnTRSW1fD4ihlcMXU4AFX1LTz27m5e3HyExKgw/vPyiVw9PVULyimlgJ4TwTk/s8gYw90v5fNGQRkrckby8PIphAZ712wT4gji8RUziAh18OvV+2hscTJnbAI/eqOQQ5UNXH7eMB64IotUP5VraO/D+Nqzm/mPFz6lvmUqLU4XP1+5h9omJ7fMzeDuReOJDg/xSzxKqXODV1cEIrIUeBxwAE8bY356xuP3ALcCTqAC+Jox5pDnsUeBK3D3R6wC7jbGGBFZAwwHGj2nWWKMOdZdHH29Inhp82H3B+VFGX36luxyGR5+s5BnPykGYGxSJD9aNoWLxif2+ly+0NDi5PY/b2GtZ87D7DHxPLx8ChNSum7qUkoFrn5fEYiIA3gCWAyUAJtFJNcYU9hht61AtjGmQUS+ATwKXC8iFwJzgame/dYBFwNrPPe/Yozpe6O/l67PGdWv44OChP++Kou0uCGICF+dPdrrq4qBEBEazB/+Tza/em8fk0fEcOXU4doMpJTqM2+ahmYBRcaYAwAi8iKwHDiVCIwxH3TYfwNwY/tDQDgQCggQAvRvtpZFRIRb542xOoxTwkMcfP+yiVaHoZQ6B3jztTYV6DigvsSzrSu3AP8CMMasBz4APvP8vGuM2dVh3z+JSL6I/Jd08ZVWRL4uInkikldRUeFFuEoppXrDp+0bInIjkA085rk/DpgEpOFOHpeIyDzP7l8xxpwHzPP8fLWzcxpjnjLGZBtjspOSknwZrlJKKbxLBKVAx+L4aZ5tpxGRRcADwDJjTLNn8zXABmNMnTGmDveVwhwAY0yp599a4G+4m6CUUkr5mTeJYDMwXkQyRCQUWAHkdtxBRGYA/4s7CXQc+XMYuFhEgkUkBHdH8S7P/UTPsSHAlcCO/r8cpZRSvdVjZ7ExxikidwLv4h4++owxZqeIPAzkGWNycTcFRQEve5r6DxtjlgGvAJcA23F3HL9jjHlDRCKBdz1JwAG8B/zB9y9PKaVUTwJiZrFSSgWynuYRBFzROaWUUqfTRKCUUgFuUDUNiUgFcKiPhycC/V+H0r805oE32OIFjdlfBlvM3cU72hjT5fj7QZUI+kNE8rprI7MjjXngDbZ4QWP2l8EWc3/i1aYhpZQKcJoIlFIqwAVSInjK6gD6QGMeeIMtXtCY/WWwxdzneAOmj0AppVTnAumKQCmlVCc0ESilVIA75xKBiCwVkT0iUiQi3+/k8XtEpFBEtonIahEZbUWcZ8TUU8x3iMh2z9oN60Qky4o4O8TTbbwd9vuiiBgRsXwInhe/45tFpMLzO84XkVutiPOMmHr8PYvIdZ6/550i8jd/x9hJPD39nn/Z4Xe8V0SqrYizQzw9xTtKRD4Qka2ez4zLrYjzjJh6inm057Ntm4isEZG0Hk9qjDlnfnAXsNsPjMG9KloBkHXGPguBCM/tbwAvDYKYYzrcXoa7eJ9t4/XsFw18hHvFuuxB8Du+GfitlXH2IebxuJeJjfPcT7Z7zGfs/x+4i1jaNl7cHbDf8NzOAort/jsGXgZu8ty+BPhzT+c9164ITi2raYxpAdqX1TzFGPOBMabBc3cD7vUVrORNzDUd7kbiruRqlR7j9fgx8DOgyZ/BdcHbmO3Em5hvA54wxpwAMKeXgLdCb3/PNwAv+CWyznkTrwFiPLeHAmV+jK8z3sScBbzvuf1BJ4+f5VxLBH1eVtNCXsUsIt8Skf3Ao8BdfoqtMz3GKyLnAyONMW/5M7BuePt38UXP5fQrIjKyk8f9yZuYJwATRORjEdkgIkv9Fl3nvH7/eZpkM/j8A8sK3sT7Q+BGESkB3sZ9FWMlb2IuAK713L4GiBaRhO5Oeq4lAq+duaym3RljnjDGjAXuBx60Op6uiEgQ8AvgXqtj6aU3gHRjzFRgFfCcxfF4Ixh389AC3N+u/yAisZZG5L0VwCvGmDarA+nBDcCzxpg04HLgz56/cTv7Lu4FwbbiXgysFOj292z3F9Rb/VlW0ypexdzBi8DVAxpR93qKNxqYAqwRkWJgNpBrcYdxj79jY0xlh7+Fp4GZfoqtK978XZQAucaYVmPMQWAv7sRgld78La/A2mYh8C7eW4C/Axhj1gPhuIu7WcWbv+UyY8y1xpgZuD/nMMZ03ylvZcfHAHSkBAMHcF9ytnekTD5jnxm4O1vGWx1vL2Ie3+H2VbhXhrNtvGfsvwbrO4u9+R0P73C7fa1tu8e8FHjOczsRd5NBgp1j9uw3ESjGM6HVzvHibjq+2XN7Eu4+Asvi9jLmRCDIc/sR4OEez2vlf8QA/aIux/3NaD/wgGfbw7i//YN7WcxyIN/zkzsIYn4c2OmJ94PuPnjtEO8Z+1qeCLz8Hf9fz++4wPM7njgIYhbczXCFuJeDXWH3mD33fwj81OpYvfwdZwEfe/4u8oElgyDmLwH7PPs8DYT1dE4tMaGUUgHuXOsjUEop1UuaCJRSKsBpIlBKqQCniUAppQKcJgKllApwmghUwBCRWBH5puf2AhF5cwCe41kR+VIv9k8XkR1dPLbGDpVb1blPE4EKJLHAN3tzgIg4BigWpWxDE4EKJD8FxopIPu4aU1GeAnO7ReSvIiIAIlIsIj8TkU+BfxORJSKyXkQ+FZGXRSTKs99PO6xt8fMOzzNfRD4RkQPtVwfi9piI7PCsLXH9mcGJyBAReVFEdonIq8CQgf6FKAXu6cpKBYrvA1OMMdNFZAHwOjAZd9mAj4G5wDrPvpXGmPNFJBH4J7DIGFMvIvcD94jIE7hLUUw0xpgzir0NBy7CXUohF3gFdzXI6cA03CUANovIR2fE9w2gwRgzSUSmAp/6+PUr1Sm9IlCBbJMxpsQY48JdPiC9w2Mvef6djafMgOdK4iZgNHAS91oLfxSRa4GGDse+ZoxxGWMKgRTPtouAF4wxbcaYcuBDIOeMeOYDfwEwxmwDtvnmZSrVPb0iUIGsY+XZNk5/P9R7/hVglTHmhjMPFpFZwBdw13a5E/dqUGeeV3wWrVIDRK8IVCCpxV0muzc2AHNFZByAiESKyARPP8FQY8zbwHdwN/l0Zy1wvYg4RCQJ97f/TWfs8xHwZc/zTAGm9jJWpfpErwhUwDDGVHpW89oBNOKuQtvTMRUicjPwgoiEeTY/iDupvC4i4bi/9d/Tw6leBebgrmJpgO8ZY46KSHqHfX4H/ElEdgG7gC3evjal+kOrjyqlVIDTpiGllApwmgiUUirAaSJQSqkAp4lAKaUCnCYCpZQKcJoIlFIqwGkiUEqpAPf/AfWztVWZ+HPFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z32RaonH5Htm"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovxPltYM5Htm"
   },
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Sprint20_segmentation_VGG16.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
