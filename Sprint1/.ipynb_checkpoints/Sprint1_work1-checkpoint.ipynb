{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テキスト全体の意図は「今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。」です。（以下の画像の箇所です）\n",
    "今回の問題2は「scikit-learnを使ってロジスティック回帰、SVM、決定木のコードを作成する」という意味で、\n",
    "問題3も「scikit-learnを使って線形回帰のコードを作成する」という意味です。\n",
    "これ以降のSprintで、3種類の分類モデルと1種類の回帰モデルをスクラッチするため、それらと対比するためここでは機械学習ライブラリscikit-learnで実装していただく、というのが今回のSprintの狙いです。\n",
    "問題2と問題3を局所的に読むと「スクラッチで実装するのかscikit-learnを使って実装するのか」わかりかねると思いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "\n",
    "\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自分で作ったがうまく動かなかった\n",
    "\n",
    "# def scratch_train_test_split(X, y, train_size=0.8, random_state = 0):\n",
    "#     rng = np.random.RandomState(seed =random_state)\n",
    "#     Xrng = rng.permutation(X)\n",
    "#     yrng = rng.permutation(y)\n",
    "    \n",
    "#     a = round(Xrng.shape[0]*train_size)\n",
    "#     X_train = Xrng[:a]\n",
    "#     X_test = Xrng[a:]\n",
    "    \n",
    "#     b = round(yrng.shape[0]*train_size)\n",
    "#     y_train = yrng[:b]\n",
    "#     y_test = yrng[b:]\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考URL: https://qiita.com/kztsh/items/5afae48b2c2fd7dc20a5\n",
    "\n",
    "def scratch_train_test_split(X, y, test_size=0.3, random_state = 0):\n",
    "    n_samples = X.shape[0]\n",
    "    #floorは切り下げ\n",
    "    n_train = np.floor((1-test_size) * n_samples).astype(int)\n",
    "    n_test = n_samples - n_train\n",
    "    \n",
    "    rng = np.random.RandomState(seed=random_state)\n",
    "    #n_samples(Xの行数100個(0~99))をランダムに並べる\n",
    "    permutation = rng.permutation(n_samples)\n",
    "    \n",
    "    #ランダムに並べられたn_samplesをn_test分上から選んでいる\n",
    "    ind_test = permutation[:n_test]\n",
    "    \n",
    "    #n_samplesだとerrorになってしまう 0~99だから\n",
    "    ind_train = permutation[n_test:(n_test + n_train)]\n",
    "    \n",
    "    #X[[2,5,86,45,0]]←下の行のはこんな感じになっている\n",
    "    X_train = X[ind_train]\n",
    "    X_test = X[ind_test]\n",
    "    y_train = y[ind_train]\n",
    "    y_test = y[ind_test]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[50:, :3]\n",
    "y = iris.target[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, test_size =0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X_train)\n",
    "\n",
    "#検証用のデータにtransformを行います。\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# sgdc = make_pipeline(StandardScaler(),SGDClassifier(loss ='log'))\n",
    "# sgdc.fit(X_train, y_train)\n",
    "# Y_pred = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = SGDClassifier(loss='log')\n",
    "sgdc.fit(X_std, y_train)\n",
    "Y_pred = sgdc.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9\n",
      "precision = 0.9285714285714286\n",
      "recall = 0.8666666666666667\n",
      "f1 score = 0.896551724137931\n",
      "confusion matrix = \n",
      "[[13  2]\n",
      " [ 1 14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, Y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, Y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, Y_pred)))\n",
    "print('f1 score = {}'.format(f1_score(y_test, Y_pred)))\n",
    "print('confusion matrix = \\n{}'.format(confusion_matrix(y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, test_size =0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svm.fit(X_train, y_train)\n",
    "Y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n",
      "precision = 1.0\n",
      "recall = 1.0\n",
      "f1 score = 1.0\n",
      "confusion matrix = \n",
      "[[65  0]\n",
      " [ 0 85]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy = {}'.format(accuracy_score(y_test, Y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, Y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, Y_pred)))\n",
    "print('f1 score = {}'.format(f1_score(y_test, Y_pred)))\n",
    "print('confusion matrix = \\n{}'.format(confusion_matrix(y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, test_size =0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_std =sc.transform(X_train)\n",
    "\n",
    "# #検証用のデータにtransformを行う\n",
    "# X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9166666666666666\n",
      "precision = 0.875\n",
      "recall = 1.0\n",
      "f1 score = 0.9333333333333333\n",
      "confusion matrix = \n",
      "[[4 1]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy = {}'.format(accuracy_score(y_test, Y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, Y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, Y_pred)))\n",
    "print('f1 score = {}'.format(f1_score(y_test, Y_pred)))\n",
    "print('confusion matrix = \\n{}'.format(confusion_matrix(y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.loc[:, ['GrLivArea','YearBuilt', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = np.log(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(np.array(df1.iloc[:, [0, 1]])\n",
    "                                                         , np.array(df1.iloc[:, [2]]), random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "#線形回帰で学習させる\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#予測を出す\n",
    "Y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均絶対誤差(MAE) =0.15353180375096603\n",
      "平均二乗誤差(MSE) = 0.044392523340521815\n",
      "二乗平均平方根誤差 (RMSE) =0.21069533298229892\n",
      "決定係数 (R2) =0.7123462478163527\n"
     ]
    }
   ],
   "source": [
    "#https://pythondatascience.plavox.info/scikit-learn/%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E8%A9%95%E4%BE%A1\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('平均絶対誤差(MAE) ={}'.format(mean_absolute_error(y_test, Y_pred)))\n",
    "print('平均二乗誤差(MSE) = {}'.format(mean_squared_error(y_test, Y_pred)))\n",
    "print('二乗平均平方根誤差 (RMSE) ={}'.format(np.sqrt(mean_squared_error(y_test, Y_pred))))\n",
    "print('決定係数 (R2) ={}'.format(r2_score(y_test, Y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
