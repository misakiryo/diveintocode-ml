{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先輩のを模写してコードリーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, *shape):\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    \n",
    "    def B(self, *shape):\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return\n",
    "    \n",
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW ** 2\n",
    "        self.HB += layer.dB ** 2\n",
    "        layer.W -= self.lr * np.sqrt(1 / self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1 / self.HB) * layer.dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploblem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleConv1d:\n",
    "    \n",
    "    def __init__(self, filter_size, initializer, optimizer, pa=0):\n",
    "        self.filter_size = filter_size\n",
    "        self.optimizer = optimizer\n",
    "        self.pa = pa\n",
    "        self.W = initializer.W(filter_size)\n",
    "        self.B = initializer.B(1)[0]\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = out_size(self.n_in, self.filter_size, self.pa)\n",
    "        \n",
    "        self.X = np.pad(X, ((self.filter_size-1), 0)) #1次元配列\n",
    "        self.X1 = np.zeros((self.filter_size, self.n_in + (self.filter_size-1)))\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[i] = np.roll(self.X, -i)\n",
    "        A = self.W @ self.X1[:, self.filter_size -1 - self.pa:self.n_in + self.pa] + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        self.dW = self.X1[:, self.filter_size -1 -self.pa:self.n_in + self.pa]@dA\n",
    "        self.dB = np.sum(dA)\n",
    "        self.dA = np.pad(dA, (0, (self.filter_size -1 )))\n",
    "        self.dA1 = np.zeros((self.filter_size, self.dA.shape[-1]))\n",
    "        for i in range(self.filter_size):\n",
    "            self.dA1[i] = np.roll(self.dA, i)\n",
    "        dX = self.W@self.dA1\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(in_size, f, p=0, s=1):\n",
    "    return int((in_size + 2*p-f) // s) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_comv1d = SimpleConv1d(filter_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01), pa=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "simple_comv1d.W = np.array([3, 5, 7], dtype = float)\n",
    "simple_comv1d.B = np.array([1], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = simple_comv1d.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([10, 20])\n",
    "delta_x = simple_comv1d.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 50.,  80., 110.]), 30)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = simple_comv1d.dW\n",
    "delta_b = simple_comv1d.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploblem 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \n",
    "    def __init__(self, filter_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0):\n",
    "        self.filter_size = filter_size\n",
    "        self.optimizer = optimizer\n",
    "        self.pa = pa\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, filter_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = out_size(self.n_in, self.filter_size, self.pa)\n",
    "        X = X.reshape(self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0, 0), ((self.filter_size-1), 0)))\n",
    "        self.X1 = np.zeros((self.n_in_channels, self.filter_size, self.n_in + (self.filter_size -1)))\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, i] = np.roll(self.X, -i, axis = -1)\n",
    "        A = np.sum(self.X1[:, :, self.filter_size -1 -self.pa:self.n_in + self.pa] * self.W[:, :, :, np.newaxis], axis =(1, 2)) + self.B.reshape(-1, 1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        self.dW = np.sum(np.dot(dA, self.X1[:, :, self.filter_size -1 -self.pa:self.n_in + self.pa, np.newaxis]), axis = -1)\n",
    "        self.dB = np.sum(dA, axis =1)\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, (self.filter_size-1))))\n",
    "        self.dA1 = np.zeros((self.n_out_channels, self.filter_size, self.dA.shape[-1]))\n",
    "        for i in range(self.filter_size):\n",
    "            self.dA1[:, i] = np.roll(self.dA, i, axis =-1)\n",
    "        dX = np.sum(self.W@self.dA1, axis = 0)\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = Conv1d(filter_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01)\n",
    "                , n_in_channels=2, n_out_channels=3, pa=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 2.],\n",
       "        [2., 1., 1.]],\n",
       "\n",
       "       [[2., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "conv1d.W = np.ones((3, 2, 3), dtype=float) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "\n",
    "conv1d.W[0,0,2] = 2\n",
    "conv1d.W[0,1,0] = 2\n",
    "conv1d.W[1,0,0] = 2\n",
    "\n",
    "conv1d.B = np.array([1, 2, 3], dtype=float) # （出力チャンネル数）\n",
    "conv1d.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 29.],\n",
       "       [18., 25.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv1d.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[9, 11], [32, 35], [52, 56]])\n",
    "delta_x = conv1d.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 31.,  51.,  71.],\n",
       "         [ 51.,  71.,  91.]],\n",
       " \n",
       "        [[102., 169., 236.],\n",
       "         [169., 236., 303.]],\n",
       " \n",
       "        [[164., 272., 380.],\n",
       "         [272., 380., 488.]]]),\n",
       " array([ 20,  67, 108]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv1d.dW\n",
    "delta_b = conv1d.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploblem 5(Adv).\n",
    "SimpleConv1dクラスとConmv1dクラスを変更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploblem 6(Adv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_2:\n",
    "    \n",
    "    def __init__(self, filter_size, initializer, optimizer, n_in_channels=1,n_out_channels=1,  pa=0):\n",
    "        self.filter_size = filter_size\n",
    "        self.optimizer = optimizer\n",
    "        self.pa = pa\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, filter_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = out_size(self.n_in, self.filter_size, self.pa)\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0, 0), (0, 0), ((self.filter_size-1), 0)))\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.filter_size, self.n_in+(self.filter_size-1)))\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, self.filter_size-1-self.pa:self.n_in+self.pa]*self.W[:, :, :, np.newaxis],\n",
    "                   axis =(2, 3)) + self.B.reshape(-1, 1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.filter_size-1-self.pa:self.n_in+self.pa],\n",
    "                        axis=(0, -1))\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, 0), (0, (self.filter_size-1))))\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.filter_size, self.dA.shape[-1]))\n",
    "        for i in range(self.filter_size):\n",
    "            self.dA1[:, :, i] = np.roll(self.dA, i, axis =-1)\n",
    "        dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1, 3))\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_2 = Conv1d_2(filter_size=3, initializer=SimpleInitializer(0.01)\n",
    "                    , optimizer = SGD(0.01), n_in_channels=1, n_out_channels=1, pa=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 5, 0, 2, 8, 1]], [[1, 5, 0, 2, 8, 1]]])\n",
    "conv1d_2.W = np.array([[[-1, 2, -1]]], dtype=float)\n",
    "conv1d_2.B = np.array([0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.,  9., -7., -4., 13., -6.]],\n",
       "\n",
       "       [[-3.,  9., -7., -4., 13., -6.]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv1d_2.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.,  0.,  0.,  0.,  0.,  0.,  7., -6.]],\n",
       "\n",
       "       [[-1.,  0.,  0.,  0.,  0.,  0.,  7., -6.]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[[1, 2, 3, 4, 5, 6]], [[1, 2, 3, 4, 5, 6]]])\n",
    "delta_x = conv1d_2.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[150., 130.,  96.]]]), array([42]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv1d_2.dW\n",
    "delta_b = conv1d_2.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_2 = Conv1d_2(filter_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01),\n",
    "                    n_in_channels=2, n_out_channels=3, pa=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 2.],\n",
       "        [2., 1., 1.]],\n",
       "\n",
       "       [[2., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]])\n",
    "conv1d_2.W = np.ones((3, 2, 3), dtype=float)\n",
    "conv1d_2.W[0, 0, 2]=2\n",
    "conv1d_2.W[0, 1, 0]=2\n",
    "conv1d_2.W[1, 0, 0]=2\n",
    "conv1d_2.B=np.array([1, 2, 3], dtype=float)\n",
    "conv1d_2.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[21., 29.],\n",
       "        [18., 25.],\n",
       "        [18., 24.]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv1d_2.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[125., 230., 204., 113.],\n",
       "        [102., 206., 195., 102.]]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[[9, 11], [32, 35], [52, 56]]])\n",
    "delta_x = conv1d_2.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 31.,  51.,  71.],\n",
       "         [ 51.,  71.,  91.]],\n",
       " \n",
       "        [[102., 169., 236.],\n",
       "         [169., 236., 303.]],\n",
       " \n",
       "        [[164., 272., 380.],\n",
       "         [272., 380., 488.]]]),\n",
       " array([ 20,  67, 108]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv1d_2.dW\n",
    "delta_b = conv1d_2.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploblem 7(Adv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_3:\n",
    "    \n",
    "    def __init__(self,filter_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0, st=1):\n",
    "        self.filter_size = filter_size\n",
    "        self.optimizer = optimizer\n",
    "        self.pa = pa\n",
    "        self.st = st\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, filter_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = out_size(self.n_in, self.filter_size, self.pa, self.st)\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0, 0), (0, 0), ((self.filter_size-1), 0)))\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.filter_size, self.n_in+(self.filter_size-1)))\n",
    "        for i in range(self.filter_size):\n",
    "            self.X1[:, :, i]=np.roll(self.X, -i, axis =-1)\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, self.filter_size-1-self.pa:self.n_in+self.pa:self.st]*self.W[:, :, :, np.newaxis],\n",
    "                  axis =(2, 3)) + self.B.reshape(-1, 1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.filter_size-1-self.pa:self.n_in+self.pa:self.st],\n",
    "                        axis =(0, -1))\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, 0), (0, (self.filter_size-1))))\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.filter_size, self.dA.shape[-1]))\n",
    "        for i in range(self.filter_size):\n",
    "            self.dA1[:, :, i] = np.roll(self.dA, i, axis =-1)\n",
    "        dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1, 3))\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_3 = Conv1d_3(filter_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01), n_in_channels=1,\n",
    "                    n_out_channels=1, pa=1, st=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1,5,0,2,8,1]]])\n",
    "conv1d_3.W = np.array([[[-1, 2, -1]]], dtype=float)\n",
    "conv1d_3.B = np.array([0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3., -7., 13.]]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv1d_3.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.,  0.,  0.,  4., -3.]]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_a = np.array([[[1,2,3]]])\n",
    "delta_x = conv1d_3.backward(delta_a)\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[16., 25., 12.]]]), array([6]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_w = conv1d_3.dW\n",
    "delta_b = conv1d_3.dB\n",
    "delta_w, delta_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return self.sigmoid(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        _sig = self.sigmoid(self.A)\n",
    "        return dZ * (1 - _sig) * _sig\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "class Tanh:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A)) ** 2)\n",
    "    \n",
    "class Softmax:\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.Z = np.exp(X) / np.sum(np.exp(X), axis =1).reshape(-1, 1)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Y):\n",
    "        self.loss = self.loss_func(Y)\n",
    "        return self.Z - Y\n",
    "    \n",
    "    def loss_func(self, Y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "    \n",
    "class ReLU:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.clip(A, 0, None)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
    "    \n",
    "class ScratchConvNeuralNetworkClassifier:\n",
    "    \n",
    "    def __init__(self, num_epoch=10, lr=0.01, batch_size=20, n_features=784, n_nodes1=400,\n",
    "                n_nodes2=200, n_output=10, verbose=True, Activater=Tanh, Optimizer=AdaGrad):\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        self.Activater = Activater\n",
    "        if Activater == Sigmoid or Activater == Tanh:\n",
    "            self.Initializer = XavierInitializer\n",
    "        elif Activater == ReLU:\n",
    "            self.Initializer = HeInitializer\n",
    "        else:\n",
    "            print('活性化関数が不適切')\n",
    "        self.Optimizer = Optimizer\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        self.val_enable = False\n",
    "        if X_val is not None:\n",
    "            self.val_enable = True\n",
    "            \n",
    "        self.conv1d_3 = Conv1d_3(filter_size=7, initializer=SimpleInitializer(0.01), optimizer=self.Optimizer(self.lr)\n",
    "                                     , n_in_channels=1, n_out_channels=1, pa=3, st=2)\n",
    "        self.conv1d_3.n_out = out_size(X.shape[-1], self.conv1d_3.filter_size, self.conv1d_3.pa, self.conv1d_3.st)\n",
    "        self.activation1 = self.Activater()\n",
    "        self.FC2 = FC(1 * self.conv1d_3.n_out, self.n_nodes2, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation2 = self.Activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation3 = Softmax()\n",
    "            \n",
    "        self.loss = []\n",
    "        self.loss_epoch = [self.activation3.loss_func(y, self.forward_propagation(X))]\n",
    "        for _ in range(self.num_epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            self.iter = len(get_mini_batch)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                self.forward_propagation(mini_X)\n",
    "                self.back_propagation(mini_X, mini_y)\n",
    "                self.loss.append(self.activation3.loss)\n",
    "            self.loss_epoch.append(self.activation3.loss_func(y, self.forward_propagation(X)))\n",
    "\n",
    "        if self.verbose:\n",
    "            self.learning_curve()\n",
    "            print()\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward_propagation(X), axis=1)\n",
    "        \n",
    "    def forward_propagation(self, X):\n",
    "        A1 = self.conv1d_3.forward(X)\n",
    "        A1 = A1.reshape(A1.shape[0], A1.shape[-1])\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        return Z3\n",
    "        \n",
    "    def back_propagation(self, X, y_true):\n",
    "        dA3 = self.activation3.backward(y_true)\n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        dA1 = dA1[:, np.newaxis]\n",
    "        dZ0 = self.conv1d_3.backward(dA1)\n",
    "            \n",
    "    def learning_curve(self):\n",
    "        plt.title('model loss')\n",
    "        plt.xlabel('num_epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.plot(np.arange(1, self.num_epoch*self.iter + 1), self.loss, label='train_loss')\n",
    "        plt.plot(np.arange(0, self.num_epoch + 1)*self.iter, self.loss_epoch, label='epoch_loss')\n",
    "        if self.val_enable:\n",
    "            plt.plot(np.arange(1, self.num_epoch + 1), self.val_loss, label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "class FC:\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X=X\n",
    "        A = X@self.W + self.B\n",
    "        return A\n",
    "        \n",
    "    def backward(self,dA):\n",
    "        dZ = dA@self.W.T\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.X.T@dA\n",
    "        self.optimizer.update(self)\n",
    "        return dZ\n",
    "    \n",
    "class XavierInitializer:\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(1 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "    \n",
    "class HeInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "    \n",
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    print(\"accuracy =\", accuracy_score(y_true, y_pred))\n",
    "    print(\"precision =\", precision_score(y_true, y_pred, average='macro'))\n",
    "    print(\"recall =\", recall_score(y_true, y_pred, average='macro'))\n",
    "    print(\"f1 =\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "1.0\n",
      "0.0\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "X_train.shape = (48000, 784)\n",
      "X_val.shape = (12000, 784)\n",
      "y_train.shape = (48000, 10)\n",
      "y_val.shape = (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(\"X_train.shape =\", X_train_.shape) # (48000, 784)\n",
    "print(\"X_val.shape =\", X_val.shape) # (12000, 784)\n",
    "print(\"y_train.shape =\", y_train_.shape) # (48000, 784)\n",
    "print(\"y_val.shape =\", y_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scratch_cnn1 = ScratchConvNeuralNetworkClassifier(num_epoch=10, lr=0.01, batch_size=20, \n",
    "                                                  n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, \n",
    "                                                  verbose=True, Activater=Tanh, Optimizer=SGD)\n",
    "scratch_cnn1.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = scratch_cnn1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.976\n",
      "precision = 0.976129862558046\n",
      "recall = 0.9757276903529771\n",
      "f1 = 0.9758954699227018\n",
      "[[ 969    0    2    1    0    2    3    2    1    0]\n",
      " [   0 1131    1    0    1    1    1    0    0    0]\n",
      " [   7    5 1000    2    1    0    3    8    5    1]\n",
      " [   0    0    4  989    0    5    0    5    4    3]\n",
      " [   2    1    2    0  949    0    3    2    1   22]\n",
      " [   2    1    0    9    1  869    5    1    3    1]\n",
      " [   4    5    1    0    2    9  933    0    2    2]\n",
      " [   0   12   10    1    3    0    0  997    0    5]\n",
      " [   1    4    3    3    3    6    2    3  944    5]\n",
      " [   0    6    0    3    7    4    1    8    1  979]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
